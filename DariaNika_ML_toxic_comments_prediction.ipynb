{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uaroAmI7Sv4"
      },
      "source": [
        "# Анализ токсичности комментариев"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8w5mQuJ7Sv4"
      },
      "source": [
        "**Техническое задание**\n",
        "\n",
        "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
        "\n",
        "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
        "\n",
        "Постройте модель со значением метрики качества <font color='red'>F1 не меньше 0.75.</font> \n",
        "\n",
        "В ходе проекта использованы библиотеки pandas, numpy, sklearn, catboost. Для предсказания токсичности комментариев используются модели логистической регрессии, дерево решений, случайный лес, градиентный бустинг Catboost. Подбор параметров наилучшей модели проведён с помощью ParameterGrid. Ключевая метрика - F1. При работе с текстами используются средства библиотеки NLTK и BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9uPQidV7Sv5"
      },
      "source": [
        "## Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Jfc4UFn7Sv5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8ouzZUJ7Sv6"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords as nltk_stopwords\n",
        "# скачать в случае отсутствия:\n",
        "#nltk.download('stopwords')\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('punkt')\n",
        "stopwords = set(nltk_stopwords.words('english'))\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-c2M_l7x7Sv7"
      },
      "source": [
        "Читаем базу данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95ZZllcm7Sv8",
        "outputId": "43d3a633-9b75-459c-9158-91ba6ace2ad0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3221</th>\n",
              "      <td>\"\\nNPVO is mostly just about the edit left by ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55972</th>\n",
              "      <td>Was not aware of this . Thanks  .Will correct</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3294</th>\n",
              "      <td>\"\\nIt says in the AIV header that warnings mus...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120188</th>\n",
              "      <td>\" But tend to agree with OP that Sukhoi is red...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111516</th>\n",
              "      <td>Right, I've removed two autoblocks that were s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87318</th>\n",
              "      <td>\"\\n\\n about asessment of Remo Fernandes \\n\\nHe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4505</th>\n",
              "      <td>\"\\n\\nResponse to your recent edit at Loyola Ac...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149451</th>\n",
              "      <td>Rewriting\\nI cut out ref to bell in NZ and fou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157405</th>\n",
              "      <td>A user misbehaving \\n\\nCheck out the talk page...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135847</th>\n",
              "      <td>\"\\n\\n Editor Topic Ban \\n\\nI'm not so sure we ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  toxic\n",
              "3221    \"\\nNPVO is mostly just about the edit left by ...      0\n",
              "55972       Was not aware of this . Thanks  .Will correct      0\n",
              "3294    \"\\nIt says in the AIV header that warnings mus...      0\n",
              "120188  \" But tend to agree with OP that Sukhoi is red...      0\n",
              "111516  Right, I've removed two autoblocks that were s...      0\n",
              "87318   \"\\n\\n about asessment of Remo Fernandes \\n\\nHe...      0\n",
              "4505    \"\\n\\nResponse to your recent edit at Loyola Ac...      0\n",
              "149451  Rewriting\\nI cut out ref to bell in NZ and fou...      0\n",
              "157405  A user misbehaving \\n\\nCheck out the talk page...      0\n",
              "135847  \"\\n\\n Editor Topic Ban \\n\\nI'm not so sure we ...      0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.read_csv('\\datasets\\toxic_comments.csv', sep= ',')\n",
        "display(df.sample(10))\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By5_sXcv7Sv8"
      },
      "source": [
        "Мы получили 159571 случай для анализа. Случай состоит из текста и разметки, является ли этот текст токсичным, что и станет нашей целевой переменной. В базе нет дубликатов и пропусков, можно приступить к следующему шагу. В данном проекте мы поступим следующим образом: \n",
        "1. векторизируем текст, используя меру TF-IDF \n",
        "2. применим логистическую регрессию и простые модели\n",
        "3. сравним результаты с градиентным бустингом Catboost по уровню F1.\n",
        "\n",
        "Для начала преобразуем тексты в <font color='red'>лемматизированные списки слов:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqdLWgyI7Sv9",
        "outputId": "a5692854-1f08-495c-ae5a-68c6ea8ae1da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\",\n",
              "       \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\"],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = df['text'].values.copy()\n",
        "corpus[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3eXQksX7Sv9",
        "outputId": "16b2cbe0-701d-4a01-eddf-d277f3ddedad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([list(['Explanation', 'Why', 'the', 'edits', 'made', 'under', 'my', 'username', 'Hardcore', 'Metallica', 'Fan', 'were', 'reverted', '?', 'They', 'were', \"n't\", 'vandalisms', ',', 'just', 'closure', 'on', 'some', 'GAs', 'after', 'I', 'voted', 'at', 'New', 'York', 'Dolls', 'FAC', '.', 'And', 'please', 'do', \"n't\", 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'I', \"'m\", 'retired', 'now.89.205.38.27']),\n",
              "       list([\"D'aww\", '!', 'He', 'matches', 'this', 'background', 'colour', 'I', \"'m\", 'seemingly', 'stuck', 'with', '.', 'Thanks', '.', '(', 'talk', ')', '21:51', ',', 'January', '11', ',', '2016', '(', 'UTC', ')'])],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for i in range(len(corpus)):\n",
        "    corpus[i] = nltk.word_tokenize(corpus[i])\n",
        "corpus[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zAqv66m7Sv9",
        "outputId": "81b0d42a-3574-4e8c-c9a6-c89af3b411d2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>lemmatized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>Explanation Why the edits made under my userna...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>D'aww ! He match this background colour I 'm s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>Hey man , I 'm really not trying to edit war ....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>`` More I ca n't make any real suggestion on i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>You , sir , are my hero . Any chance you remem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159566</th>\n",
              "      <td>\":::::And for the second time of asking, when ...</td>\n",
              "      <td>0</td>\n",
              "      <td>`` : : : : : And for the second time of asking...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159567</th>\n",
              "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
              "      <td>0</td>\n",
              "      <td>You should be ashamed of yourself That is a ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159568</th>\n",
              "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Spitzer Umm , there no actual article for pros...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159569</th>\n",
              "      <td>And it looks like it was actually you who put ...</td>\n",
              "      <td>0</td>\n",
              "      <td>And it look like it wa actually you who put on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159570</th>\n",
              "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
              "      <td>0</td>\n",
              "      <td>`` And ... I really do n't think you understan...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159571 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  toxic  \\\n",
              "0       Explanation\\nWhy the edits made under my usern...      0   \n",
              "1       D'aww! He matches this background colour I'm s...      0   \n",
              "2       Hey man, I'm really not trying to edit war. It...      0   \n",
              "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4       You, sir, are my hero. Any chance you remember...      0   \n",
              "...                                                   ...    ...   \n",
              "159566  \":::::And for the second time of asking, when ...      0   \n",
              "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
              "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
              "159569  And it looks like it was actually you who put ...      0   \n",
              "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
              "\n",
              "                                          lemmatized_text  \n",
              "0       Explanation Why the edits made under my userna...  \n",
              "1       D'aww ! He match this background colour I 'm s...  \n",
              "2       Hey man , I 'm really not trying to edit war ....  \n",
              "3       `` More I ca n't make any real suggestion on i...  \n",
              "4       You , sir , are my hero . Any chance you remem...  \n",
              "...                                                   ...  \n",
              "159566  `` : : : : : And for the second time of asking...  \n",
              "159567  You should be ashamed of yourself That is a ho...  \n",
              "159568  Spitzer Umm , there no actual article for pros...  \n",
              "159569  And it look like it wa actually you who put on...  \n",
              "159570  `` And ... I really do n't think you understan...  \n",
              "\n",
              "[159571 rows x 3 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['lemmatized_text'] = [' '.join([WordNetLemmatizer().lemmatize(word) for word in text]) for text in corpus]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dym0MIQC7Sv-",
        "outputId": "dc9bee4c-f0de-47b6-cb5b-6b153bd39cd5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>lemmatized_text</th>\n",
              "      <th>cleared_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>Explanation Why the edits made under my userna...</td>\n",
              "      <td>Explanation Why the edits made under my userna...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>D'aww ! He match this background colour I 'm s...</td>\n",
              "      <td>D aww He match this background colour I m seem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>Hey man , I 'm really not trying to edit war ....</td>\n",
              "      <td>Hey man I m really not trying to edit war It s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>`` More I ca n't make any real suggestion on i...</td>\n",
              "      <td>More I ca n t make any real suggestion on impr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>You , sir , are my hero . Any chance you remem...</td>\n",
              "      <td>You sir are my hero Any chance you remember wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159566</th>\n",
              "      <td>\":::::And for the second time of asking, when ...</td>\n",
              "      <td>0</td>\n",
              "      <td>`` : : : : : And for the second time of asking...</td>\n",
              "      <td>And for the second time of asking when your vi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159567</th>\n",
              "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
              "      <td>0</td>\n",
              "      <td>You should be ashamed of yourself That is a ho...</td>\n",
              "      <td>You should be ashamed of yourself That is a ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159568</th>\n",
              "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Spitzer Umm , there no actual article for pros...</td>\n",
              "      <td>Spitzer Umm there no actual article for prosti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159569</th>\n",
              "      <td>And it looks like it was actually you who put ...</td>\n",
              "      <td>0</td>\n",
              "      <td>And it look like it wa actually you who put on...</td>\n",
              "      <td>And it look like it wa actually you who put on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159570</th>\n",
              "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
              "      <td>0</td>\n",
              "      <td>`` And ... I really do n't think you understan...</td>\n",
              "      <td>And I really do n t think you understand I cam...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159571 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  toxic  \\\n",
              "0       Explanation\\nWhy the edits made under my usern...      0   \n",
              "1       D'aww! He matches this background colour I'm s...      0   \n",
              "2       Hey man, I'm really not trying to edit war. It...      0   \n",
              "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4       You, sir, are my hero. Any chance you remember...      0   \n",
              "...                                                   ...    ...   \n",
              "159566  \":::::And for the second time of asking, when ...      0   \n",
              "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
              "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
              "159569  And it looks like it was actually you who put ...      0   \n",
              "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
              "\n",
              "                                          lemmatized_text  \\\n",
              "0       Explanation Why the edits made under my userna...   \n",
              "1       D'aww ! He match this background colour I 'm s...   \n",
              "2       Hey man , I 'm really not trying to edit war ....   \n",
              "3       `` More I ca n't make any real suggestion on i...   \n",
              "4       You , sir , are my hero . Any chance you remem...   \n",
              "...                                                   ...   \n",
              "159566  `` : : : : : And for the second time of asking...   \n",
              "159567  You should be ashamed of yourself That is a ho...   \n",
              "159568  Spitzer Umm , there no actual article for pros...   \n",
              "159569  And it look like it wa actually you who put on...   \n",
              "159570  `` And ... I really do n't think you understan...   \n",
              "\n",
              "                                             cleared_text  \n",
              "0       Explanation Why the edits made under my userna...  \n",
              "1       D aww He match this background colour I m seem...  \n",
              "2       Hey man I m really not trying to edit war It s...  \n",
              "3       More I ca n t make any real suggestion on impr...  \n",
              "4       You sir are my hero Any chance you remember wh...  \n",
              "...                                                   ...  \n",
              "159566  And for the second time of asking when your vi...  \n",
              "159567  You should be ashamed of yourself That is a ho...  \n",
              "159568  Spitzer Umm there no actual article for prosti...  \n",
              "159569  And it look like it wa actually you who put on...  \n",
              "159570  And I really do n t think you understand I cam...  \n",
              "\n",
              "[159571 rows x 4 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['cleared_text'] = [\" \".join(re.sub(r'[^a-zA-Z ]', ' ', text).split()) for text in df['lemmatized_text']]\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcGnW4hn7Sv-"
      },
      "source": [
        "<font color='red'>Разделим</font> данные на тренировочную и тестовую выборки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EodsS0R37Sv_"
      },
      "outputs": [],
      "source": [
        "X = df.cleared_text\n",
        "y = df.toxic\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=23)\n",
        "print(X.shape, y.shape)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlg1fRJH7Sv_"
      },
      "source": [
        "Мы положили в выборку 10% случаев, то есть 15958 текстов. <font color='red'>Векторизируем</font> их, чтобы с ними могли работать простые модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEV0xwH97Sv_",
        "outputId": "a6cc28de-bd9d-45ca-a10c-5b815c2f7ea4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<143613x155045 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 3929633 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<15958x155045 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 421502 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fitted_vectorizer = TfidfVectorizer(stop_words=stopwords).fit(X_train)\n",
        "tf_idf_train = fitted_vectorizer.transform(X_train)\n",
        "tf_idf_test = fitted_vectorizer.transform(X_test)\n",
        "\n",
        "# для отображения полученных матриц можно воспользоваться следующим кодом, но сейчас мы сэкономим память и делать этого не будем\n",
        "#tf_idf_train = pd.DataFrame.sparse.from_spmatrix(tf_idf_train)\n",
        "#tf_idf_test = pd.DataFrame.sparse.from_spmatrix(tf_idf_test)\n",
        "\n",
        "display(tf_idf_train)\n",
        "display(tf_idf_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBAp99iX7SwA"
      },
      "outputs": [],
      "source": [
        "print(tf_idf_train.shape, y_train.shape)\n",
        "print(tf_idf_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfP4yd9a7SwA"
      },
      "source": [
        "### Вывод\n",
        "\n",
        "Итак, мы подготовили данные для отработки алгоритма классификации текстов на токсичные и нет с помощью простых моделей (логистическая регрессия, дерево решений и случайный лес). Тексты токенизированы, лемматизированы и затем векторизированы так, что у нас вместо текста теперь 174274 дихотомические переменные для описания этого текста в категориях 0 и 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BtdSX4k7SwA"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nsUJGu67SwA"
      },
      "source": [
        "### Модель линейной регрессии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNRcDjp47SwA",
        "outputId": "2f166437-691f-485c-d99b-096730e6d715"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.74804</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model       F1\n",
              "0  Logistic Regression  0.74804"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LogisticRegression(random_state=12345, class_weight='balanced', solver = 'sag')\n",
        "model.fit(tf_idf_train, y_train)\n",
        "predictions = model.predict(tf_idf_test)\n",
        "current_model = pd.DataFrame({'Model': ['Logistic Regression'],\n",
        "              'F1': [f1_score(y_test, predictions)]})\n",
        "all_models = current_model.merge(current_model, how = 'outer')\n",
        "all_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK3HnQw-7SwB"
      },
      "source": [
        "Мы сразу получили результат, близкий к выполнению технического требования заказчика. Посмотрим, чего можно добиться с помощью изменения гиперпараметра С:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gu4Ce1IG7SwB"
      },
      "outputs": [],
      "source": [
        "#с помощью данного кода удалось найти наилучшее значение гиперпараметра С на уровне 9.9. \n",
        "#т.к. код работает слишком долго, повторно он не запускался.\n",
        "\n",
        "param_grid = {'C': np.logspace(-5, 2, 50)}\n",
        "best_score = 0\n",
        "for c in ParameterGrid(param_grid):\n",
        "    model.set_params(**c)\n",
        "    model.fit(tf_idf_train, y_train)\n",
        "    predictions = model.predict(tf_idf_test)\n",
        "    if f1_score(y_test, predictions) > best_score:\n",
        "        best_score = f1_score(y_test, predictions)\n",
        "        best_grid = c\n",
        "\n",
        "print(\"F1: %0.2f\" % best_score)\n",
        "print(\"Grid:\", best_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7cSb4-G7SwB",
        "outputId": "254f9207-5062-474b-e2f3-67d0df41fb5f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.761072</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model        F1\n",
              "0  Logistic Regression  0.761072"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LogisticRegression(random_state=12345, class_weight='balanced', solver = 'sag', max_iter = 1000, C = 7)\n",
        "model.fit(tf_idf_train, y_train)\n",
        "predictions = model.predict(tf_idf_test)\n",
        "current_model = pd.DataFrame({'Model': ['Logistic Regression'],\n",
        "              'F1': [f1_score(y_test, predictions)]})\n",
        "all_models = current_model.merge(current_model, how = 'outer')\n",
        "all_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPfmQk2j7SwB"
      },
      "source": [
        "### Модель случайного леса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQcBU-h77SwC",
        "outputId": "472d8a11-f1a1-48d0-9967-07b441e703bd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.761072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.678327</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model        F1\n",
              "0  Logistic Regression  0.761072\n",
              "1        Random Forest  0.678327"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = RandomForestClassifier(random_state = 23, n_estimators = 20)\n",
        "model.fit(tf_idf_train, y_train)\n",
        "predictions = model.predict(tf_idf_test)\n",
        "current_model = pd.DataFrame({'Model': ['Random Forest'],\n",
        "              'F1': [f1_score(y_test, predictions)]})\n",
        "all_models = all_models.merge(current_model, how = 'outer')\n",
        "all_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8KiU_BM7SwC"
      },
      "source": [
        "### Модель дерева решений"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eqx20DhB7SwC",
        "outputId": "0930bd8d-9e1f-42e8-c059-59c1e092c0ba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.761072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.678327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.709658</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model        F1\n",
              "0  Logistic Regression  0.761072\n",
              "1        Random Forest  0.678327\n",
              "2        Decision Tree  0.709658"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = DecisionTreeClassifier(random_state = 23)\n",
        "model.fit(tf_idf_train, y_train)\n",
        "predictions = model.predict(tf_idf_test)\n",
        "current_model = pd.DataFrame({'Model': ['Decision Tree'],\n",
        "              'F1': [f1_score(y_test, predictions)]})\n",
        "all_models = all_models.merge(current_model, how = 'outer')\n",
        "all_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqjs9l8K7SwC"
      },
      "source": [
        "<font color='red'>Логистическая регрессия отвечает требованиям технического задания.</font> F1-мера на тестовой выборке выше 0,76. Посмотрим, чего можно добиться с помощью Catboost, для которой бы не понадобилась токенизация, лемматизация и векторизация текста, которую мы проделали на этапе предобработки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PorEkPQG7SwC"
      },
      "source": [
        "### Градиентный бустинг Catboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfm0vPKR7SwC"
      },
      "source": [
        "В текущей среде не поддерживается работа модели CatBoost с текстовыми переменными, поэтому мы приведём код, который был запущен в другой среде и ниже приведём скриншот результата."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er_rREJf7SwC",
        "outputId": "0bbc5219-556f-4cdf-bf28-cc040ee4c2f9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.761072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.678327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.709658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Catboost</td>\n",
              "      <td>0.765119</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model        F1\n",
              "0  Logistic Regression  0.761072\n",
              "1        Random Forest  0.678327\n",
              "2        Decision Tree  0.709658\n",
              "3             Catboost  0.765119"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_cat = pd.DataFrame(X_train)\n",
        "X_test_cat = pd.DataFrame(X_test)\n",
        "\n",
        "model = CatBoostClassifier(verbose = 10, eval_metric = 'F1')\n",
        "model.fit(X_train_cat, y_train, text_features=['cleared_text'])\n",
        "predictions = model.predict(X_test_cat)\n",
        "current_model = pd.DataFrame({'Model': ['Catboost'],\n",
        "              'F1': [f1_score(y_test, predictions)]})\n",
        "all_models = all_models.merge(current_model, how = 'outer')\n",
        "all_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQmk2rQr7SwD"
      },
      "source": [
        "## Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Hu44Tonh7SwD"
      },
      "source": [
        "Добавим недостающие библиотеки и модули"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LVe2Ari97SwD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import BertTokenizer\n",
        "from tqdm import notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "i6n8CTiZ7SwD"
      },
      "source": [
        "Выбираем модель и токенизатор"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "k511CIFf7SwE"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = transformers.BertModel.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ZaX1c76v7SwE"
      },
      "source": [
        "У нас недостаточно ресурса для исследования всей базы, сделаем выборку в 400 случаев.\n",
        "Отберём позитивные и токсичные комментарии в равных пропорциях"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0NPPEIi37SwE",
        "outputId": "88625f3b-6ee5-41d8-ce00-0cdd33e67f6c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>weights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>82243</td>\n",
              "      <td>\"\\n\\n Please do not vandalize pages, as you di...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>151131</td>\n",
              "      <td>LGBT \\n\\nyou little fuck , are you a fag , tha...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>122095</td>\n",
              "      <td>FUCK YOU! FUCK EVERYBODY HERE AND THEIR FUCKIN...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44657</td>\n",
              "      <td>remove your head from your butt \\n\\nNeilN need...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34962</td>\n",
              "      <td>That may be appalling but what's really appall...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>135287</td>\n",
              "      <td>Your Lie(s) About Me \\nI've never put a lie on...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>114961</td>\n",
              "      <td>, you are making a fool of yourself!! This is ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>158007</td>\n",
              "      <td>gay charver that no one likes</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>70886</td>\n",
              "      <td>That sentence and link should be deleted unles...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>40021</td>\n",
              "      <td>O RLY? \\n\\nTake your last warning, and shove i...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index                                               text  toxic  weights\n",
              "0     82243  \"\\n\\n Please do not vandalize pages, as you di...      0      0.1\n",
              "1    151131  LGBT \\n\\nyou little fuck , are you a fag , tha...      1      0.9\n",
              "2    122095  FUCK YOU! FUCK EVERYBODY HERE AND THEIR FUCKIN...      1      0.9\n",
              "3     44657  remove your head from your butt \\n\\nNeilN need...      1      0.9\n",
              "4     34962  That may be appalling but what's really appall...      1      0.9\n",
              "..      ...                                                ...    ...      ...\n",
              "395  135287  Your Lie(s) About Me \\nI've never put a lie on...      1      0.9\n",
              "396  114961  , you are making a fool of yourself!! This is ...      1      0.9\n",
              "397  158007                      gay charver that no one likes      1      0.9\n",
              "398   70886  That sentence and link should be deleted unles...      0      0.1\n",
              "399   40021  O RLY? \\n\\nTake your last warning, and shove i...      1      0.9\n",
              "\n",
              "[400 rows x 4 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('\\datasets\\toxic_comments.csv', sep= ',')\n",
        "df['weights'] = df['toxic']\n",
        "df['weights'] = df['weights'].replace({0:0.1, 1:0.9})\n",
        "df = df.sample(400, random_state=23, weights = df.weights)\n",
        "df['text'] = df['text'][:][0:512]\n",
        "df.reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "v_efzsTf7SwE"
      },
      "source": [
        "Токенизируем текст"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Hb9lPdAn7SwE"
      },
      "outputs": [],
      "source": [
        "tokenized = df['text'].apply(\n",
        "    lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
        "\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "WSTd37xs7SwF"
      },
      "source": [
        "Чтобы строки матрицы по каждому тексту были одинаковые по длине, добавим нули в конце там, где длина короче максимума.\n",
        "Длины срок придётся сократить до 512 чисел, ограничение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AJpRI1An7SwF"
      },
      "outputs": [],
      "source": [
        "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
        "padded = padded[:, 0:512]\n",
        "attention_mask = np.where(padded != 0, 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Pcj14Jme7SwF"
      },
      "source": [
        "Сформируем эмбеддинги на выборке по частям"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "referenced_widgets": [
            "6b6b1df0869240529d1e4ff6986e6101"
          ]
        },
        "id": "XR8oO7sX7SwF",
        "outputId": "b0e5671a-2835-4182-f443-44e68fd5c4cd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b6b1df0869240529d1e4ff6986e6101",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch_size = 100\n",
        "embeddings = []\n",
        "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
        "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
        "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
        "\n",
        "    embeddings.append(batch_embeddings[0][:,0,:].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "i8umG2DY7SwF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7LvXq1pF7SwF"
      },
      "outputs": [],
      "source": [
        "features = np.concatenate(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zacoiKlt7SwF"
      },
      "source": [
        "Обучаем логистическую регрессию на полученном массиве:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4dhXT9e17SwF",
        "outputId": "e41d05e4-399c-4a35-ac75-0e6b1f926947"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.761072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.678327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.709658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Catboost</td>\n",
              "      <td>0.765119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Logistic regression with BERT</td>\n",
              "      <td>0.818653</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Model        F1\n",
              "0            Logistic Regression  0.761072\n",
              "1                  Random Forest  0.678327\n",
              "2                  Decision Tree  0.709658\n",
              "3                       Catboost  0.765119\n",
              "4  Logistic regression with BERT  0.818653"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, df['toxic'], test_size=0.5, random_state=23)\n",
        "model = LogisticRegression(random_state=23, class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "predict = model.predict(X_test)\n",
        "\n",
        "current_model = pd.DataFrame({'Model': ['Logistic regression with BERT'],\n",
        "                              'F1': [f1_score(y_test, predict)]})\n",
        "all_models = all_models.merge(current_model, how = 'outer')\n",
        "all_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD_ra41k7SwG"
      },
      "source": [
        "## Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejtsd1ZH7SwG"
      },
      "source": [
        "Итак, <font color='red'>мы создали модель, комплексная оценка точности и отзывчивости которой находится на уровне 82%</font>, что превышает установленный в техническом задании порог. Наилучшей моделью оказалась логистическая регрессия на эмбеддингах, созданных с помощью BERT, однако работу данной модели необходимо проверить на большей выборке, что требует много ресурсов. Логистическая регрессия, проведённая на векторизированном с помощью TF-IDF тексте, требует гораздоб меньше ресурсов, быстро обучается на всей базе и показывает результат на уровне 75%, что достаточно для выполнения технческого требования. Существенным преимуществом данной модели является скорость её обучения и предсказания, однако для её работы необходима существенная предобработка (токенизация, лемматизация и векторизация текста), как и в случаае с работой через BERT. Catboost не требует преобработки, что может стать аргументом в пользу использования именно этой модели. В различных условиях применения следует выбирать из данных моделей."
      ]
    }
  ],
  "metadata": {
    "ExecuteTimeLog": [
      {
        "duration": 7380,
        "start_time": "2022-03-01T12:05:17.687Z"
      },
      {
        "duration": 85,
        "start_time": "2022-03-01T12:59:10.501Z"
      },
      {
        "duration": 696,
        "start_time": "2022-03-01T13:01:31.039Z"
      },
      {
        "duration": 700,
        "start_time": "2022-03-01T13:01:39.971Z"
      },
      {
        "duration": 698,
        "start_time": "2022-03-01T13:03:29.145Z"
      },
      {
        "duration": 678,
        "start_time": "2022-03-01T13:03:37.193Z"
      },
      {
        "duration": 6630,
        "start_time": "2022-03-01T13:04:34.449Z"
      },
      {
        "duration": 93,
        "start_time": "2022-03-01T13:05:10.333Z"
      },
      {
        "duration": 6466,
        "start_time": "2022-03-01T13:05:20.071Z"
      },
      {
        "duration": 7,
        "start_time": "2022-03-01T13:06:29.528Z"
      },
      {
        "duration": 4,
        "start_time": "2022-03-01T13:07:11.147Z"
      },
      {
        "duration": 223,
        "start_time": "2022-03-01T13:15:12.193Z"
      },
      {
        "duration": 275,
        "start_time": "2022-03-01T13:15:32.068Z"
      },
      {
        "duration": 918,
        "start_time": "2022-03-01T13:15:56.367Z"
      },
      {
        "duration": 107482,
        "start_time": "2022-03-01T13:49:41.088Z"
      },
      {
        "duration": 259,
        "start_time": "2022-03-01T13:51:32.711Z"
      },
      {
        "duration": 28230,
        "start_time": "2022-03-01T13:51:46.432Z"
      },
      {
        "duration": -311,
        "start_time": "2022-03-01T13:52:14.975Z"
      },
      {
        "duration": 4,
        "start_time": "2022-03-01T13:52:21.142Z"
      },
      {
        "duration": 341118,
        "start_time": "2022-03-01T13:52:34.277Z"
      },
      {
        "duration": 9,
        "start_time": "2022-03-01T13:58:32.093Z"
      },
      {
        "duration": 7,
        "start_time": "2022-03-01T13:58:43.604Z"
      },
      {
        "duration": 6,
        "start_time": "2022-03-01T13:58:56.072Z"
      },
      {
        "duration": 31,
        "start_time": "2022-03-01T14:11:40.312Z"
      },
      {
        "duration": 6,
        "start_time": "2022-03-01T14:24:50.878Z"
      },
      {
        "duration": 703,
        "start_time": "2022-03-01T14:30:16.070Z"
      },
      {
        "duration": 331,
        "start_time": "2022-03-01T14:33:14.585Z"
      },
      {
        "duration": 688,
        "start_time": "2022-03-01T14:35:02.459Z"
      },
      {
        "duration": 5,
        "start_time": "2022-03-01T14:37:13.721Z"
      },
      {
        "duration": 7,
        "start_time": "2022-03-01T14:38:58.979Z"
      },
      {
        "duration": 4,
        "start_time": "2022-03-01T15:14:29.107Z"
      },
      {
        "duration": 280,
        "start_time": "2022-03-01T15:18:32.202Z"
      },
      {
        "duration": 356,
        "start_time": "2022-03-02T09:43:14.448Z"
      },
      {
        "duration": 1548,
        "start_time": "2022-03-02T09:43:22.243Z"
      },
      {
        "duration": 227,
        "start_time": "2022-03-02T09:43:23.794Z"
      },
      {
        "duration": 881,
        "start_time": "2022-03-02T09:43:24.024Z"
      },
      {
        "duration": 6,
        "start_time": "2022-03-02T09:43:24.907Z"
      },
      {
        "duration": 58,
        "start_time": "2022-03-02T09:43:24.915Z"
      },
      {
        "duration": 367,
        "start_time": "2022-03-02T09:43:24.981Z"
      },
      {
        "duration": -316,
        "start_time": "2022-03-02T09:43:25.667Z"
      },
      {
        "duration": -323,
        "start_time": "2022-03-02T09:43:25.675Z"
      },
      {
        "duration": -323,
        "start_time": "2022-03-02T09:43:25.677Z"
      },
      {
        "duration": -323,
        "start_time": "2022-03-02T09:43:25.678Z"
      },
      {
        "duration": 861,
        "start_time": "2022-03-02T10:44:40.216Z"
      },
      {
        "duration": 5,
        "start_time": "2022-03-02T10:46:05.377Z"
      },
      {
        "duration": 146828,
        "start_time": "2022-03-02T10:49:31.022Z"
      },
      {
        "duration": 73135,
        "start_time": "2022-03-02T11:00:25.682Z"
      },
      {
        "duration": 95,
        "start_time": "2022-03-02T12:01:29.344Z"
      },
      {
        "duration": 35692,
        "start_time": "2022-03-02T12:02:49.574Z"
      },
      {
        "duration": 33421,
        "start_time": "2022-03-02T12:06:54.019Z"
      },
      {
        "duration": 11,
        "start_time": "2022-03-02T12:12:21.483Z"
      },
      {
        "duration": 94899,
        "start_time": "2022-03-02T12:13:27.833Z"
      },
      {
        "duration": 259,
        "start_time": "2022-03-02T12:16:27.560Z"
      },
      {
        "duration": 39,
        "start_time": "2022-03-02T12:17:08.316Z"
      },
      {
        "duration": 214553,
        "start_time": "2022-03-02T12:17:17.467Z"
      },
      {
        "duration": 2012,
        "start_time": "2022-03-02T12:26:47.184Z"
      },
      {
        "duration": 293,
        "start_time": "2022-03-02T12:26:49.199Z"
      },
      {
        "duration": 1277,
        "start_time": "2022-03-02T12:26:49.496Z"
      },
      {
        "duration": 11,
        "start_time": "2022-03-02T12:26:50.777Z"
      },
      {
        "duration": 141787,
        "start_time": "2022-03-02T12:26:50.790Z"
      },
      {
        "duration": 76015,
        "start_time": "2022-03-02T12:29:12.580Z"
      },
      {
        "duration": 41,
        "start_time": "2022-03-02T12:30:28.598Z"
      },
      {
        "duration": 204996,
        "start_time": "2022-03-02T12:30:28.642Z"
      },
      {
        "duration": 8,
        "start_time": "2022-03-02T12:38:31.788Z"
      },
      {
        "duration": 7,
        "start_time": "2022-03-02T12:38:42.397Z"
      },
      {
        "duration": 7,
        "start_time": "2022-03-02T12:39:49.094Z"
      },
      {
        "duration": 41,
        "start_time": "2022-03-02T12:40:33.826Z"
      },
      {
        "duration": 209590,
        "start_time": "2022-03-02T12:40:40.915Z"
      },
      {
        "duration": 8,
        "start_time": "2022-03-02T12:45:27.680Z"
      },
      {
        "duration": 1472,
        "start_time": "2022-03-02T12:46:29.235Z"
      },
      {
        "duration": 212,
        "start_time": "2022-03-02T12:46:30.710Z"
      },
      {
        "duration": 866,
        "start_time": "2022-03-02T12:46:30.925Z"
      },
      {
        "duration": 10,
        "start_time": "2022-03-02T12:46:31.795Z"
      },
      {
        "duration": 140804,
        "start_time": "2022-03-02T12:46:31.809Z"
      },
      {
        "duration": 74519,
        "start_time": "2022-03-02T12:48:52.616Z"
      },
      {
        "duration": 52,
        "start_time": "2022-03-02T12:50:07.138Z"
      },
      {
        "duration": 74482,
        "start_time": "2022-03-02T12:50:07.193Z"
      },
      {
        "duration": -1469,
        "start_time": "2022-03-02T12:51:23.147Z"
      },
      {
        "duration": 204209,
        "start_time": "2022-03-02T12:52:29.818Z"
      },
      {
        "duration": 5,
        "start_time": "2022-03-02T12:55:54.030Z"
      },
      {
        "duration": 306,
        "start_time": "2022-03-02T13:02:47.231Z"
      },
      {
        "duration": 3435,
        "start_time": "2022-03-02T13:03:48.307Z"
      },
      {
        "duration": 3606,
        "start_time": "2022-03-02T13:06:05.557Z"
      },
      {
        "duration": 3419,
        "start_time": "2022-03-02T13:07:02.062Z"
      },
      {
        "duration": 311,
        "start_time": "2022-03-02T13:07:45.942Z"
      },
      {
        "duration": 3588,
        "start_time": "2022-03-02T13:08:16.749Z"
      },
      {
        "duration": 14333,
        "start_time": "2022-03-02T13:10:58.487Z"
      },
      {
        "duration": 34619,
        "start_time": "2022-03-02T13:13:34.959Z"
      },
      {
        "duration": 5,
        "start_time": "2022-03-02T13:15:06.058Z"
      },
      {
        "duration": 289,
        "start_time": "2022-03-02T13:15:09.860Z"
      },
      {
        "duration": 14634,
        "start_time": "2022-03-02T13:15:22.539Z"
      },
      {
        "duration": 15700,
        "start_time": "2022-03-02T13:36:23.151Z"
      },
      {
        "duration": 226358,
        "start_time": "2022-03-02T13:36:38.854Z"
      },
      {
        "duration": 803061,
        "start_time": "2022-03-02T13:40:25.216Z"
      },
      {
        "duration": 238,
        "start_time": "2022-03-02T14:05:26.324Z"
      },
      {
        "duration": 4,
        "start_time": "2022-03-02T14:05:40.919Z"
      },
      {
        "duration": 304,
        "start_time": "2022-03-02T14:07:22.032Z"
      },
      {
        "duration": 1481,
        "start_time": "2022-03-02T14:07:33.206Z"
      },
      {
        "duration": 366,
        "start_time": "2022-03-02T14:07:42.859Z"
      },
      {
        "duration": 1464,
        "start_time": "2022-03-02T14:10:48.203Z"
      },
      {
        "duration": 222,
        "start_time": "2022-03-02T14:10:49.669Z"
      },
      {
        "duration": 937,
        "start_time": "2022-03-02T14:10:49.894Z"
      },
      {
        "duration": 11,
        "start_time": "2022-03-02T14:10:50.833Z"
      },
      {
        "duration": 163921,
        "start_time": "2022-03-02T14:10:50.847Z"
      },
      {
        "duration": 74647,
        "start_time": "2022-03-02T14:13:34.773Z"
      },
      {
        "duration": 51,
        "start_time": "2022-03-02T14:14:49.422Z"
      },
      {
        "duration": 33500,
        "start_time": "2022-03-02T14:14:49.477Z"
      },
      {
        "duration": 5,
        "start_time": "2022-03-02T14:15:22.980Z"
      },
      {
        "duration": 14706,
        "start_time": "2022-03-02T14:15:22.987Z"
      },
      {
        "duration": 212994,
        "start_time": "2022-03-02T14:15:37.695Z"
      },
      {
        "duration": 6,
        "start_time": "2022-03-02T14:34:35.768Z"
      },
      {
        "duration": 6,
        "start_time": "2022-03-02T14:34:36.384Z"
      },
      {
        "duration": 781,
        "start_time": "2022-03-02T14:34:36.393Z"
      },
      {
        "duration": 9,
        "start_time": "2022-03-02T14:34:37.177Z"
      },
      {
        "duration": 147513,
        "start_time": "2022-03-02T14:34:37.189Z"
      },
      {
        "duration": 74325,
        "start_time": "2022-03-02T14:37:04.705Z"
      },
      {
        "duration": 63,
        "start_time": "2022-03-02T14:38:19.033Z"
      },
      {
        "duration": 35458,
        "start_time": "2022-03-02T14:38:19.099Z"
      },
      {
        "duration": 15,
        "start_time": "2022-03-02T14:38:54.559Z"
      },
      {
        "duration": 15424,
        "start_time": "2022-03-02T14:38:54.577Z"
      },
      {
        "duration": 214455,
        "start_time": "2022-03-02T14:39:10.003Z"
      },
      {
        "duration": 821520,
        "start_time": "2022-03-02T14:42:53.792Z"
      },
      {
        "duration": 10,
        "start_time": "2022-03-02T15:03:47.855Z"
      },
      {
        "duration": 251,
        "start_time": "2022-03-02T15:03:57.945Z"
      },
      {
        "duration": 14,
        "start_time": "2022-03-02T15:06:23.427Z"
      },
      {
        "duration": 55,
        "start_time": "2022-03-02T15:07:12.986Z"
      },
      {
        "duration": 235,
        "start_time": "2022-03-02T15:08:10.447Z"
      },
      {
        "duration": 9,
        "start_time": "2022-03-02T15:08:31.491Z"
      },
      {
        "duration": 9,
        "start_time": "2022-03-02T15:08:45.072Z"
      },
      {
        "duration": 13,
        "start_time": "2022-03-02T15:08:53.620Z"
      },
      {
        "duration": 18,
        "start_time": "2022-03-02T15:09:16.803Z"
      },
      {
        "duration": 267,
        "start_time": "2022-03-02T15:09:42.758Z"
      },
      {
        "duration": 14,
        "start_time": "2022-03-02T15:09:54.102Z"
      },
      {
        "duration": 300,
        "start_time": "2022-03-02T15:11:20.750Z"
      },
      {
        "duration": 1516,
        "start_time": "2022-03-02T15:13:57.766Z"
      },
      {
        "duration": 222,
        "start_time": "2022-03-02T15:13:59.285Z"
      },
      {
        "duration": 903,
        "start_time": "2022-03-02T15:13:59.510Z"
      },
      {
        "duration": 10,
        "start_time": "2022-03-02T15:14:00.416Z"
      },
      {
        "duration": 140862,
        "start_time": "2022-03-02T15:14:00.429Z"
      },
      {
        "duration": 76190,
        "start_time": "2022-03-02T15:16:21.294Z"
      },
      {
        "duration": 45,
        "start_time": "2022-03-02T15:17:37.487Z"
      },
      {
        "duration": 35851,
        "start_time": "2022-03-02T15:17:37.536Z"
      },
      {
        "duration": 5,
        "start_time": "2022-03-02T15:18:13.390Z"
      },
      {
        "duration": 14895,
        "start_time": "2022-03-02T15:18:13.398Z"
      },
      {
        "duration": 224747,
        "start_time": "2022-03-02T15:18:28.296Z"
      },
      {
        "duration": 803185,
        "start_time": "2022-03-02T15:22:13.046Z"
      },
      {
        "duration": 15451,
        "start_time": "2022-03-02T15:35:36.233Z"
      },
      {
        "duration": 18,
        "start_time": "2022-03-02T17:35:23.558Z"
      },
      {
        "duration": 1390,
        "start_time": "2022-03-04T04:37:17.100Z"
      },
      {
        "duration": 218,
        "start_time": "2022-03-04T04:37:18.493Z"
      },
      {
        "duration": 801,
        "start_time": "2022-03-04T04:37:18.714Z"
      },
      {
        "duration": 11,
        "start_time": "2022-03-04T04:37:19.517Z"
      },
      {
        "duration": 135651,
        "start_time": "2022-03-04T04:37:19.530Z"
      },
      {
        "duration": 71662,
        "start_time": "2022-03-04T04:39:35.183Z"
      },
      {
        "duration": 50,
        "start_time": "2022-03-04T04:40:46.848Z"
      },
      {
        "duration": 31484,
        "start_time": "2022-03-04T04:40:46.901Z"
      },
      {
        "duration": 5,
        "start_time": "2022-03-04T04:41:18.388Z"
      },
      {
        "duration": 14804,
        "start_time": "2022-03-04T04:41:18.395Z"
      },
      {
        "duration": 5,
        "start_time": "2022-03-04T06:37:09.657Z"
      },
      {
        "duration": 7,
        "start_time": "2022-03-04T06:38:08.686Z"
      },
      {
        "duration": 404,
        "start_time": "2022-03-04T06:38:38.529Z"
      },
      {
        "duration": 7,
        "start_time": "2022-03-04T06:39:10.531Z"
      },
      {
        "duration": 276345,
        "start_time": "2022-03-04T06:40:54.685Z"
      },
      {
        "duration": 265,
        "start_time": "2022-03-04T06:45:56.542Z"
      },
      {
        "duration": 273,
        "start_time": "2022-03-04T06:46:26.329Z"
      },
      {
        "duration": 2226783,
        "start_time": "2022-03-04T06:46:46.441Z"
      },
      {
        "duration": 14666,
        "start_time": "2022-03-04T07:25:26.221Z"
      },
      {
        "duration": 89,
        "start_time": "2022-03-04T07:29:17.377Z"
      },
      {
        "duration": 219,
        "start_time": "2022-03-04T07:29:55.050Z"
      },
      {
        "duration": 5,
        "start_time": "2022-03-04T07:31:00.529Z"
      },
      {
        "duration": 1451,
        "start_time": "2022-03-04T07:31:07.753Z"
      },
      {
        "duration": 1584,
        "start_time": "2022-03-04T07:32:20.319Z"
      },
      {
        "duration": 652121,
        "start_time": "2022-03-04T07:32:30.486Z"
      },
      {
        "duration": 78,
        "start_time": "2022-03-04T07:48:57.307Z"
      },
      {
        "duration": 81,
        "start_time": "2022-03-04T07:49:23.244Z"
      },
      {
        "duration": 360785,
        "start_time": "2022-03-04T07:50:14.439Z"
      },
      {
        "duration": -8635,
        "start_time": "2022-03-04T07:56:23.865Z"
      },
      {
        "duration": 14698,
        "start_time": "2022-03-04T07:56:31.199Z"
      },
      {
        "duration": 65369,
        "start_time": "2022-03-04T07:57:02.532Z"
      },
      {
        "duration": 81975,
        "start_time": "2022-03-04T07:59:12.327Z"
      },
      {
        "duration": 247237,
        "start_time": "2022-03-04T08:04:08.214Z"
      },
      {
        "duration": 18126,
        "start_time": "2022-03-04T08:11:44.041Z"
      },
      {
        "duration": 18567,
        "start_time": "2022-03-04T08:12:17.431Z"
      },
      {
        "duration": 75302,
        "start_time": "2022-03-04T08:12:53.376Z"
      },
      {
        "duration": 857634,
        "start_time": "2022-03-04T08:15:28.852Z"
      },
      {
        "duration": 7,
        "start_time": "2022-03-04T08:30:15.766Z"
      },
      {
        "duration": 6,
        "start_time": "2022-03-04T08:30:27.433Z"
      },
      {
        "duration": 19179,
        "start_time": "2022-03-04T08:30:42.268Z"
      },
      {
        "duration": 73715,
        "start_time": "2022-03-04T08:32:59.873Z"
      },
      {
        "duration": 24323,
        "start_time": "2022-03-04T08:34:22.791Z"
      },
      {
        "duration": 6,
        "start_time": "2022-03-04T08:35:10.222Z"
      },
      {
        "duration": 6895,
        "start_time": "2022-03-04T08:35:28.251Z"
      },
      {
        "duration": 4544,
        "start_time": "2022-03-04T08:35:47.937Z"
      },
      {
        "duration": 4719,
        "start_time": "2022-03-04T08:36:06.745Z"
      },
      {
        "duration": 9222,
        "start_time": "2022-03-04T08:37:20.060Z"
      },
      {
        "duration": 17490,
        "start_time": "2022-03-04T08:37:36.824Z"
      },
      {
        "duration": 17377,
        "start_time": "2022-03-04T08:38:03.621Z"
      },
      {
        "duration": 17122,
        "start_time": "2022-03-04T08:38:26.086Z"
      },
      {
        "duration": 17164,
        "start_time": "2022-03-04T08:38:47.798Z"
      },
      {
        "duration": 17394,
        "start_time": "2022-03-04T08:39:16.975Z"
      },
      {
        "duration": 17597,
        "start_time": "2022-03-04T08:39:38.612Z"
      },
      {
        "duration": 17482,
        "start_time": "2022-03-04T08:40:15.359Z"
      },
      {
        "duration": 17570,
        "start_time": "2022-03-04T08:40:44.810Z"
      },
      {
        "duration": 17472,
        "start_time": "2022-03-04T08:41:05.985Z"
      },
      {
        "duration": 6,
        "start_time": "2022-03-04T08:43:47.749Z"
      },
      {
        "duration": 6,
        "start_time": "2022-03-04T08:44:08.063Z"
      },
      {
        "duration": 17427,
        "start_time": "2022-03-04T08:44:26.462Z"
      },
      {
        "duration": 18111,
        "start_time": "2022-03-04T08:45:32.006Z"
      },
      {
        "duration": 17793,
        "start_time": "2022-03-04T08:47:01.546Z"
      },
      {
        "duration": 17182,
        "start_time": "2022-03-04T08:47:32.391Z"
      },
      {
        "duration": 16961,
        "start_time": "2022-03-04T08:48:16.313Z"
      },
      {
        "duration": 18031,
        "start_time": "2022-03-04T08:49:37.445Z"
      },
      {
        "duration": 18018,
        "start_time": "2022-03-04T08:50:21.047Z"
      },
      {
        "duration": 17844,
        "start_time": "2022-03-04T08:50:54.764Z"
      },
      {
        "duration": 17818,
        "start_time": "2022-03-04T08:51:24.505Z"
      },
      {
        "duration": 17221,
        "start_time": "2022-03-04T08:51:52.267Z"
      },
      {
        "duration": 17713,
        "start_time": "2022-03-04T08:52:17.363Z"
      },
      {
        "duration": 17706,
        "start_time": "2022-03-04T08:53:09.029Z"
      },
      {
        "duration": 17534,
        "start_time": "2022-03-04T08:53:41.178Z"
      },
      {
        "duration": 17244,
        "start_time": "2022-03-04T08:54:18.982Z"
      },
      {
        "duration": 17640,
        "start_time": "2022-03-04T08:54:44.619Z"
      },
      {
        "duration": 1022,
        "start_time": "2022-03-04T09:03:01.877Z"
      },
      {
        "duration": 6,
        "start_time": "2022-03-04T09:32:48.387Z"
      },
      {
        "duration": 4,
        "start_time": "2022-03-04T09:32:48.419Z"
      },
      {
        "duration": 769,
        "start_time": "2022-03-04T09:32:48.448Z"
      },
      {
        "duration": 8,
        "start_time": "2022-03-04T09:32:49.220Z"
      },
      {
        "duration": 140671,
        "start_time": "2022-03-04T09:32:49.231Z"
      },
      {
        "duration": 72071,
        "start_time": "2022-03-04T09:35:09.904Z"
      },
      {
        "duration": 10,
        "start_time": "2022-03-04T09:36:21.977Z"
      },
      {
        "duration": 744,
        "start_time": "2022-03-04T09:39:06.664Z"
      },
      {
        "duration": 458,
        "start_time": "2022-03-04T09:39:34.651Z"
      },
      {
        "duration": 86,
        "start_time": "2022-03-04T09:41:40.188Z"
      },
      {
        "duration": 11365,
        "start_time": "2022-03-04T09:41:53.242Z"
      },
      {
        "duration": 14,
        "start_time": "2022-03-04T09:43:33.224Z"
      },
      {
        "duration": 6,
        "start_time": "2022-03-04T09:43:46.466Z"
      },
      {
        "duration": 5,
        "start_time": "2022-03-04T09:44:26.396Z"
      },
      {
        "duration": 2970,
        "start_time": "2022-03-04T09:45:02.439Z"
      },
      {
        "duration": 41,
        "start_time": "2022-03-04T09:45:49.360Z"
      },
      {
        "duration": 72,
        "start_time": "2022-03-04T09:47:15.708Z"
      },
      {
        "duration": 21888,
        "start_time": "2022-03-04T09:49:00.887Z"
      },
      {
        "duration": 5,
        "start_time": "2022-03-04T09:50:35.379Z"
      },
      {
        "duration": 7829,
        "start_time": "2022-03-04T09:51:22.921Z"
      },
      {
        "duration": 41,
        "start_time": "2022-03-04T09:52:06.671Z"
      },
      {
        "duration": 20233,
        "start_time": "2022-03-04T09:52:15.491Z"
      },
      {
        "duration": 5,
        "start_time": "2022-03-04T09:52:44.917Z"
      },
      {
        "duration": 7586,
        "start_time": "2022-03-04T09:54:00.919Z"
      },
      {
        "duration": 17512,
        "start_time": "2022-03-04T09:54:59.651Z"
      },
      {
        "duration": 7725,
        "start_time": "2022-03-04T09:55:29.804Z"
      },
      {
        "duration": 608,
        "start_time": "2022-03-04T09:55:54.421Z"
      },
      {
        "duration": 4224,
        "start_time": "2022-03-04T09:56:00.267Z"
      },
      {
        "duration": 3328,
        "start_time": "2022-03-04T09:56:10.117Z"
      },
      {
        "duration": 5238,
        "start_time": "2022-03-04T09:56:18.063Z"
      },
      {
        "duration": 6431,
        "start_time": "2022-03-04T09:56:29.500Z"
      },
      {
        "duration": 7666,
        "start_time": "2022-03-04T09:57:00.220Z"
      },
      {
        "duration": 16957,
        "start_time": "2022-03-04T09:57:19.036Z"
      },
      {
        "duration": 16433,
        "start_time": "2022-03-04T09:57:54.764Z"
      },
      {
        "duration": 17009,
        "start_time": "2022-03-04T09:58:20.951Z"
      },
      {
        "duration": 16669,
        "start_time": "2022-03-04T09:59:12.082Z"
      },
      {
        "duration": 16690,
        "start_time": "2022-03-04T09:59:38.003Z"
      },
      {
        "duration": 16256,
        "start_time": "2022-03-04T10:01:00.857Z"
      },
      {
        "duration": 17021,
        "start_time": "2022-03-04T10:01:27.862Z"
      },
      {
        "duration": 16483,
        "start_time": "2022-03-04T10:01:53.540Z"
      },
      {
        "duration": 16090,
        "start_time": "2022-03-04T10:02:22.626Z"
      },
      {
        "duration": 16146,
        "start_time": "2022-03-04T10:02:46.356Z"
      },
      {
        "duration": 17869,
        "start_time": "2022-03-04T10:03:09.010Z"
      },
      {
        "duration": 17508,
        "start_time": "2022-03-04T10:03:34.848Z"
      },
      {
        "duration": 16548,
        "start_time": "2022-03-04T10:04:11.098Z"
      },
      {
        "duration": 16576,
        "start_time": "2022-03-04T10:04:54.184Z"
      },
      {
        "duration": 16908,
        "start_time": "2022-03-04T10:05:15.638Z"
      },
      {
        "duration": 16915,
        "start_time": "2022-03-04T10:05:38.182Z"
      },
      {
        "duration": 17020,
        "start_time": "2022-03-04T10:06:00.113Z"
      },
      {
        "duration": 16866,
        "start_time": "2022-03-04T10:06:22.475Z"
      },
      {
        "duration": 16931,
        "start_time": "2022-03-04T10:06:45.165Z"
      },
      {
        "duration": 16658,
        "start_time": "2022-03-04T10:07:09.987Z"
      },
      {
        "duration": 17295,
        "start_time": "2022-03-04T10:07:41.593Z"
      },
      {
        "duration": 16763,
        "start_time": "2022-03-04T10:08:08.282Z"
      },
      {
        "duration": 17062,
        "start_time": "2022-03-04T10:08:37.447Z"
      },
      {
        "duration": 16703,
        "start_time": "2022-03-04T10:09:03.035Z"
      },
      {
        "duration": 17431,
        "start_time": "2022-03-04T10:09:28.402Z"
      },
      {
        "duration": 19852,
        "start_time": "2022-03-04T10:09:58.762Z"
      },
      {
        "duration": 17821,
        "start_time": "2022-03-04T10:10:26.968Z"
      },
      {
        "duration": 16717,
        "start_time": "2022-03-04T10:11:09.492Z"
      },
      {
        "duration": 72,
        "start_time": "2022-03-04T10:13:03.424Z"
      },
      {
        "duration": 1385,
        "start_time": "2022-03-04T10:24:40.202Z"
      },
      {
        "duration": 203,
        "start_time": "2022-03-04T10:24:41.590Z"
      },
      {
        "duration": 840,
        "start_time": "2022-03-04T10:24:41.796Z"
      },
      {
        "duration": 15,
        "start_time": "2022-03-04T10:24:42.639Z"
      },
      {
        "duration": 136765,
        "start_time": "2022-03-04T10:24:42.657Z"
      },
      {
        "duration": 75164,
        "start_time": "2022-03-04T10:26:59.424Z"
      },
      {
        "duration": 2816,
        "start_time": "2022-03-04T10:28:14.591Z"
      },
      {
        "duration": 39,
        "start_time": "2022-03-04T10:28:17.409Z"
      },
      {
        "duration": 20420,
        "start_time": "2022-03-04T10:28:17.450Z"
      },
      {
        "duration": 14,
        "start_time": "2022-03-04T10:28:37.872Z"
      },
      {
        "duration": 7788,
        "start_time": "2022-03-04T10:28:37.889Z"
      },
      {
        "duration": 8,
        "start_time": "2022-03-04T10:28:45.679Z"
      },
      {
        "duration": 17322,
        "start_time": "2022-03-04T10:28:45.690Z"
      },
      {
        "duration": 178232,
        "start_time": "2022-03-04T10:29:03.015Z"
      },
      {
        "duration": 1417,
        "start_time": "2022-03-04T10:38:35.390Z"
      },
      {
        "duration": 208,
        "start_time": "2022-03-04T10:38:36.810Z"
      },
      {
        "duration": 822,
        "start_time": "2022-03-04T10:38:37.021Z"
      },
      {
        "duration": 9,
        "start_time": "2022-03-04T10:38:37.846Z"
      },
      {
        "duration": 140395,
        "start_time": "2022-03-04T10:38:37.857Z"
      },
      {
        "duration": 75446,
        "start_time": "2022-03-04T10:40:58.255Z"
      },
      {
        "duration": 2906,
        "start_time": "2022-03-04T10:42:13.703Z"
      },
      {
        "duration": 37,
        "start_time": "2022-03-04T10:42:16.613Z"
      },
      {
        "duration": 21459,
        "start_time": "2022-03-04T10:42:16.653Z"
      },
      {
        "duration": 6,
        "start_time": "2022-03-04T10:42:38.115Z"
      },
      {
        "duration": 7711,
        "start_time": "2022-03-04T10:42:38.124Z"
      },
      {
        "duration": 4,
        "start_time": "2022-03-04T10:42:45.838Z"
      },
      {
        "duration": 168144,
        "start_time": "2022-03-04T10:42:45.845Z"
      },
      {
        "duration": 186141,
        "start_time": "2022-03-04T10:45:33.991Z"
      },
      {
        "duration": 1362,
        "start_time": "2022-03-04T10:54:24.229Z"
      },
      {
        "duration": 213,
        "start_time": "2022-03-04T10:54:25.594Z"
      },
      {
        "duration": 829,
        "start_time": "2022-03-04T10:54:25.810Z"
      },
      {
        "duration": 13,
        "start_time": "2022-03-04T10:54:26.643Z"
      },
      {
        "duration": 142492,
        "start_time": "2022-03-04T10:54:26.659Z"
      },
      {
        "duration": 20105,
        "start_time": "2022-03-04T10:58:05.107Z"
      },
      {
        "duration": 6,
        "start_time": "2022-03-04T10:58:25.215Z"
      },
      {
        "duration": 8121,
        "start_time": "2022-03-04T10:58:25.223Z"
      },
      {
        "duration": 3,
        "start_time": "2022-03-04T10:58:33.346Z"
      },
      {
        "duration": 17585,
        "start_time": "2022-03-04T10:58:33.351Z"
      },
      {
        "duration": 177028,
        "start_time": "2022-03-04T10:59:17.238Z"
      },
      {
        "duration": 166679,
        "start_time": "2022-03-04T11:06:43.293Z"
      },
      {
        "duration": 168981,
        "start_time": "2022-03-04T11:11:18.107Z"
      },
      {
        "duration": 172719,
        "start_time": "2022-03-04T11:14:30.473Z"
      },
      {
        "duration": 167260,
        "start_time": "2022-03-04T11:17:36.358Z"
      },
      {
        "duration": 182956,
        "start_time": "2022-03-04T11:20:45.907Z"
      },
      {
        "duration": 728672,
        "start_time": "2022-03-04T11:23:48.866Z"
      },
      {
        "duration": 422,
        "start_time": "2022-03-04T11:35:57.541Z"
      },
      {
        "duration": -802,
        "start_time": "2022-03-04T11:35:58.768Z"
      },
      {
        "duration": 4,
        "start_time": "2022-03-04T11:47:20.746Z"
      },
      {
        "duration": 19,
        "start_time": "2022-03-04T11:47:31.318Z"
      },
      {
        "duration": 292,
        "start_time": "2022-03-04T17:19:47.635Z"
      },
      {
        "duration": 1422,
        "start_time": "2022-03-04T17:20:13.554Z"
      },
      {
        "duration": 212,
        "start_time": "2022-03-04T17:20:14.978Z"
      },
      {
        "duration": 803,
        "start_time": "2022-03-04T17:20:15.193Z"
      },
      {
        "duration": 9,
        "start_time": "2022-03-04T17:20:15.999Z"
      },
      {
        "duration": 133093,
        "start_time": "2022-03-04T17:20:16.011Z"
      },
      {
        "duration": 69090,
        "start_time": "2022-03-04T17:22:29.107Z"
      },
      {
        "duration": 2706,
        "start_time": "2022-03-04T17:23:38.199Z"
      },
      {
        "duration": 37,
        "start_time": "2022-03-04T17:23:40.909Z"
      },
      {
        "duration": 20449,
        "start_time": "2022-03-04T17:23:40.948Z"
      },
      {
        "duration": 6,
        "start_time": "2022-03-04T17:24:01.400Z"
      },
      {
        "duration": 7409,
        "start_time": "2022-03-04T17:24:01.409Z"
      },
      {
        "duration": 4,
        "start_time": "2022-03-04T17:24:08.820Z"
      },
      {
        "duration": 162095,
        "start_time": "2022-03-04T17:24:08.826Z"
      },
      {
        "duration": 177180,
        "start_time": "2022-03-04T17:26:50.923Z"
      },
      {
        "duration": 693498,
        "start_time": "2022-03-04T17:29:48.106Z"
      },
      {
        "duration": 18,
        "start_time": "2022-03-04T17:41:21.607Z"
      }
    ],
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Содержание",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "302.391px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "DariaNika_ML_toxic_comments_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "K9uPQidV7Sv5",
        "9BtdSX4k7SwA",
        "5nsUJGu67SwA",
        "HPfmQk2j7SwB",
        "r8KiU_BM7SwC",
        "UQmk2rQr7SwD",
        "PD_ra41k7SwG"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}